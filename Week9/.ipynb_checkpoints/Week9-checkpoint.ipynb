{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV2 Image Processing Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros(10000).reshape(100,100)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.circle(img, center, radius, color[, thickness[, lineType[, shift]]])\n",
    "cv2.circle(img, (50,50), 30, (255,255,255), 2)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.fillConvexPoly(img, points, color[, lineType[, shift]])\n",
    "#cv2.fillPoly(img, pts, color[, lineType[, shift[, offset]]]) \n",
    "img = np.zeros(10000).reshape(100,100)\n",
    "cv2.fillConvexPoly(img, np.array([[5,5],[100,20], [60,100],[5,5]]), (255,255,255))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.line(img, pt1, pt2, color[, thickness[, lineType[, shift]]])\n",
    "img = np.zeros(10000).reshape(100,100)\n",
    "cv2.line(img, (5,5), (100,100), (255,255,255))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.rectangle(img, pt1, pt2, color[, thickness[, lineType[, shift]]])\n",
    "img = np.zeros(10000).reshape(100,100)\n",
    "cv2.rectangle(img, (5,5), (50,50), (255,255,255))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.putText(img, text, org, fontFace, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "img = np.zeros(10000).reshape(100,100)\n",
    "cv2.putText(img, 'Hello World!', (5, 50), 2, 0.4, (255,255,255))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/bmw.jpg', 0)  #0 for grayscale, 1 for RGB\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('./data/bmwgray.png',img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Two Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('./data/bmw.jpg', 0)\n",
    "img2 = cv2.imread('./data/logo.jpeg', 0)\n",
    "\n",
    "a, b = img2.shape\n",
    "img1 = img1[:a,:b]\n",
    "\n",
    "dst = cv2.addWeighted(img1,0.7,img2,0.3,0)\n",
    "\n",
    "plt.imshow(dst, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/bmw.jpg',0)\n",
    "rows,cols = img.shape\n",
    "\n",
    "M = np.float32([[1,0,200], [0,1,50]])\n",
    "dst = cv2.warpAffine(img, M, (cols,rows))\n",
    "\n",
    "plt.imshow(dst, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotating Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/bmw.jpg',0)\n",
    "rows,cols = img.shape\n",
    "\n",
    "M = cv2.getRotationMatrix2D((cols/2,rows/2),45,1)\n",
    "dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "plt.imshow(dst, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/template.jpg')\n",
    "rows,cols,ch = img.shape\n",
    "\n",
    "pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
    "pts2 = np.float32([[10,100],[200,50],[100,250]])\n",
    "\n",
    "M = cv2.getAffineTransform(pts1,pts2)\n",
    "\n",
    "dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/template.jpg')\n",
    "rows,cols,ch = img.shape\n",
    "\n",
    "pts1 = np.float32([[100,200],[600,200],[100,600],[600,600]])\n",
    "pts2 = np.float32([[0,0],[700,0],[0,700],[700,700]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "\n",
    "dst = cv2.warpPerspective(img,M,(700,700))\n",
    "\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/template.jpg',0)\n",
    "edges = cv2.Canny(img,100,300)\n",
    "plt.figure(figsize = (20, 20))\n",
    "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with 3 corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = cv2.imread('./data/template.jpg', 0)\n",
    "\n",
    "upper_left = template[:50, :50]\n",
    "upper_right = template[:50, 650:]\n",
    "lower_left = template[650:, :50]\n",
    "lower_right = template[650:, 650:]\n",
    "upper_left[:, :], upper_right[:, :], lower_left[:, :], lower_right[:, :] = 0, 0, 0, 0\n",
    "upper_left[7:44, 7:44], upper_right[7:44, 7:44], lower_left[7:44, 7:44], lower_right[1:-1, 1:-1] = 255, 255, 255, 255\n",
    "upper_left[14:37, 14:37], upper_right[14:37, 14:37], lower_left[14:37, 14:37] = 0, 0, 0\n",
    "\n",
    "plt.figure(figsize = (7, 7))\n",
    "cv2.imwrite('./data/template1.jpg', template)\n",
    "plt.imshow(template, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/template1.jpg', 0)\n",
    "cimg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1, 20, param1=50, param2=30, minRadius=20, maxRadius=30)\n",
    "\n",
    "circles = np.uint16(np.around(circles)) # x-col, y-row\n",
    "# print(len(circles[0]))\n",
    "for i in circles[0, :]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(cimg, (i[0], i[1]), i[2], (0, 255, 0), 2)\n",
    "    # draw the center of the circle\n",
    "    cv2.circle(cimg, (i[0], i[1]), 2, (0, 0, 255), 3)\n",
    "    \n",
    "plt.figure(figsize=(7,7))    \n",
    "plt.imshow(cimg)\n",
    "# plt.show()\n",
    "\n",
    "# cv2.imwrite('circle_detected.jpg', cimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "def position(x, y):\n",
    "    d = {1:'A', 2:'B', 3:'C', 4:'D'}\n",
    "    if x < 350:\n",
    "        question = math.ceil((y - 250) / 50.0)\n",
    "        variant = math.ceil((x - 150) / 50.0)\n",
    "    else:\n",
    "        question = math.ceil(7 + (y - 250) / 50.0)\n",
    "        variant = math.ceil((x - 400) / 50.0)\n",
    "    return question, d[variant]\n",
    "\n",
    "print(position(325, 325))\n",
    "\n",
    "def generate_random_solution():\n",
    "    test = []\n",
    "    variants = ['A', 'B', 'C', 'D']\n",
    "    for i in range(1, 15):\n",
    "        test.append((i, random.choice(variants)))\n",
    "    return test\n",
    "\n",
    "print(generate_random_solution())\n",
    "\n",
    "def coordinate(n, v):\n",
    "    d = {'A':1, 'B':2, 'C':3, 'D':4}\n",
    "    if n < 8:\n",
    "        col = 125 + 50 * d[v]\n",
    "        row = 225 + 50 * n\n",
    "    else:\n",
    "        col = 375 + 50 * d[v]\n",
    "        row = 225 + 50 * (n - 7)\n",
    "    return col, row\n",
    "\n",
    "print(coordinate(2, 'D'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/template1.jpg', 0)\n",
    "cimg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "for each in generate_random_solution():\n",
    "    a, b = coordinate(each[0], each[1])\n",
    "    cv2.circle(cimg, (a, b), 2, (0, 0, 0), 40)\n",
    "    \n",
    "plt.figure(figsize=(7,7))    \n",
    "plt.imshow(cimg)\n",
    "\n",
    "cv2.imwrite('./data/circle_answered.jpg', cimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Random Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/circle_answered.jpg', 0)\n",
    "cimg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                            param1=50, param2=30, minRadius=20, maxRadius=30)\n",
    "\n",
    "circles = np.uint16(np.around(circles)) # x-col, y-row\n",
    "\n",
    "def check(a, b, r):\n",
    "    array = []\n",
    "    for j in range(a-r, a+r+1):\n",
    "        for k in range(b-r, b+r+1):\n",
    "            if (a-j)**2 + (b-k)**2 <= r**2:\n",
    "                array.append(img[k, j])\n",
    "    return np.sum(np.array(array)) / float(len(array))\n",
    "answers = {}\n",
    "for i in circles[0]:\n",
    "    if check(i[0], i[1], i[2]) < 50:\n",
    "        answers[position(i[0], i[1])[0]] = position(i[0], i[1])[1]\n",
    "print([(i, answers[i]) for i in range(1, 15)])\n",
    "# plt.figure(figsize=(7,7))    \n",
    "# plt.imshow(cimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "im = cv2.imread('./data/template1.jpg')\n",
    "imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "ret,thresh = cv2.threshold(imgray,127,255,0)\n",
    "im2, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for i in range(len(contours)):\n",
    "    area = cv2.contourArea(contours[i])\n",
    "    if area < 600 and area > 500:\n",
    "        print(contours[i])\n",
    "        print(area)\n",
    "        cv2.drawContours(imgray, contours, i, (0,255,0), 3)\n",
    "\n",
    "#cv2.drawContours(imgray, contours, -1, (0,255,0), 3) all contours\n",
    "    \n",
    "plt.figure(figsize=(10,10))    \n",
    "plt.imshow(imgray, cmap='gray')\n",
    "\n",
    "# cv2.imshow('img',im)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three Corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = np.zeros((23,23))\n",
    "plt.imshow(bb, cmap='gray')\n",
    "cv2.imwrite('./data/black_box.jpg', bb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img_rgb = cv2.imread('./data/template1.jpg', 0)\n",
    "# img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "template = cv2.imread('./data/black_box.jpg',0)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "res = cv2.matchTemplate(img_rgb,template,cv2.TM_CCOEFF_NORMED)\n",
    "threshold = 0.8\n",
    "loc = np.where( res >= threshold)\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n",
    "\n",
    "plt.imshow(img_rgb, cmap='gray')\n",
    "plt.show()\n",
    "    \n",
    "# cv2.imwrite('./data/trying.png', img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('/home/musab/anaconda3/share/OpenCV/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('/home/musab/anaconda3/share/OpenCV/haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('./data/real.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 3)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)  \n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "       cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "plt.figure(figsize=(20,7))    \n",
    "plt.imshow(img)\n",
    "    \n",
    "# cv2.imshow('img',img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('/home/musab/anaconda3/share/OpenCV/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('/home/musab/anaconda3/share/OpenCV/haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('./data/barca.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 3)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)  \n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "       cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "plt.figure(figsize=(20,7))    \n",
    "plt.imshow(img)\n",
    "    \n",
    "# cv2.imshow('img',img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('/home/musab/anaconda3/share/OpenCV/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('/home/musab/anaconda3/share/OpenCV/haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('./data/president.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 3)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)  \n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "       cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "# plt.figure(figsize=(20,7))    \n",
    "# plt.imshow(img)\n",
    "    \n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "\n",
    "# Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "# Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Display the resulting frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
